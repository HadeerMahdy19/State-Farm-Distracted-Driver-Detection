{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"directory = '../input/state-farm-distracted-driver-detection/imgs/train'","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:04:52.340011Z","iopub.execute_input":"2022-07-04T09:04:52.341708Z","iopub.status.idle":"2022-07-04T09:04:52.362622Z","shell.execute_reply.started":"2022-07-04T09:04:52.341614Z","shell.execute_reply":"2022-07-04T09:04:52.361992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras as keras\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.applications.imagenet_utils import preprocess_input\n\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1./255,\n    validation_split=0.2\n)\nimage_size = (256, 256)\nbatch_size = 32\ntrain_generator = datagen.flow_from_directory(\n    directory,\n    class_mode='categorical',\n    target_size=image_size,\n    batch_size=batch_size,\n    subset='training'\n)\nval_generator = datagen.flow_from_directory(\n    directory,\n    class_mode='categorical',\n    target_size=image_size,\n    batch_size=batch_size,\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:05:00.290359Z","iopub.execute_input":"2022-07-04T09:05:00.290861Z","iopub.status.idle":"2022-07-04T09:05:20.225144Z","shell.execute_reply.started":"2022-07-04T09:05:00.290834Z","shell.execute_reply":"2022-07-04T09:05:20.224144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(val_generator)[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:05:20.226351Z","iopub.execute_input":"2022-07-04T09:05:20.226605Z","iopub.status.idle":"2022-07-04T09:05:20.570615Z","shell.execute_reply.started":"2022-07-04T09:05:20.226565Z","shell.execute_reply":"2022-07-04T09:05:20.569642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\nbase.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:05:20.573618Z","iopub.execute_input":"2022-07-04T09:05:20.573899Z","iopub.status.idle":"2022-07-04T09:05:21.223874Z","shell.execute_reply.started":"2022-07-04T09:05:20.573875Z","shell.execute_reply":"2022-07-04T09:05:21.222931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:05:21.225128Z","iopub.execute_input":"2022-07-04T09:05:21.225392Z","iopub.status.idle":"2022-07-04T09:05:21.327389Z","shell.execute_reply.started":"2022-07-04T09:05:21.225368Z","shell.execute_reply":"2022-07-04T09:05:21.326465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:05:21.328733Z","iopub.execute_input":"2022-07-04T09:05:21.329036Z","iopub.status.idle":"2022-07-04T09:05:21.336557Z","shell.execute_reply.started":"2022-07-04T09:05:21.329005Z","shell.execute_reply":"2022-07-04T09:05:21.335492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam', # optimizers.RMSprop(lr=2e-5),\n    metrics=['acc']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:06:56.474998Z","iopub.execute_input":"2022-07-04T09:06:56.475406Z","iopub.status.idle":"2022-07-04T09:06:56.484632Z","shell.execute_reply.started":"2022-07-04T09:06:56.475379Z","shell.execute_reply":"2022-07-04T09:06:56.48394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch=560,\n    epochs=3,\n    validation_data=val_generator,\n    validation_steps=140\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:07:19.221386Z","iopub.execute_input":"2022-07-04T09:07:19.221733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'], '--')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'], '--')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('trans_model_no_fine_tune.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_base.trainable = True\n\nset_trainable = False\nfor layer in base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam', # optimizers.RMSprop(lr=2e-5),\n    metrics=['acc']\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('trans_model_fine_tune.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch=560,\n    epochs=3,\n    validation_data=val_generator,\n    validation_steps=140\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'], '--')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'], '--')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_tensor = next(train_generator)[0][0:1]\nprint(img_tensor.shape)\nplt.imshow(img_tensor[0])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_count = 6\nlayer_outputs = [layer.output for layer in model.layers[:conv_count]]\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\nactivation_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activations = activation_model.predict(img_tensor)\nfirst_layer_activation = activations[0]\nplt.matshow(first_layer_activation[0, :, :, 3], cmap='viridis')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_names = []\nfor layer in model.layers[:conv_count]:\n    layer_names.append(layer.name)\n\nimages_per_row = 16\n\n# Now let's display our feature maps\nfor layer_name, layer_activation in zip(layer_names, activations):\n    # This is the number of features in the feature map\n    n_features = layer_activation.shape[-1]\n\n    # The feature map has shape (1, size, size, n_features)\n    size = layer_activation.shape[1]\n\n    # We will tile the activation channels in this matrix\n    n_cols = n_features // images_per_row\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n\n    # We'll tile each filter into this big horizontal grid\n    for col in range(n_cols):\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            # Post-process the feature to make it visually palatable\n            channel_image -= channel_image.mean()\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size,\n                         row * size : (row + 1) * size] = channel_image\n\n    # Display the grid\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n    \nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}